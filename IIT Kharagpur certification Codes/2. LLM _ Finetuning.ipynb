{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "%pip install datasets\n",
        "%pip install huggingface\n",
        "%pip install evaluate"
      ],
      "metadata": {
        "id": "GPCDYA-caNr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import evaluate\n",
        "\n",
        "from datasets import load_dataset\n",
        "from transformers import GPT2Tokenizer\n",
        "from transformers import GPT2ForSequenceClassification\n",
        "from transformers import TrainingArguments, Trainer\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "tBQktWg8aqtm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Skip WanDB Integration - used for logging\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ],
      "metadata": {
        "id": "TmlOCj3uGMEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAysoxlKYk72"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "dataset = load_dataset(\"mteb/tweet_sentiment_extraction\")\n",
        "df = pd.DataFrame(dataset['train'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the dataset\n",
        "df.head()"
      ],
      "metadata": {
        "id": "kSVFMlH9aFcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the prompt using the tokenizer\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "\n",
        "# Replace the pad_token with eos_token\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Function to tokenize each examples\n",
        "def tokenize_function(examples):\n",
        "   return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "# Tokenized dataset\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "id": "kb4dnLT-avgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset into TRAIN and EVAL partition\n",
        "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
        "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))"
      ],
      "metadata": {
        "id": "btvlAfURbDet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We select a small fragment of the data for illustration due to resource limitations\n",
        "\n",
        "small_train_dataset = small_train_dataset.select(range(100))\n",
        "small_eval_dataset = small_eval_dataset.select(range(100))"
      ],
      "metadata": {
        "id": "OsK3wuBrUfZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model\n",
        "model = GPT2ForSequenceClassification.from_pretrained(\"gpt2\", num_labels=3)"
      ],
      "metadata": {
        "id": "FbdkEi6ibKv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the metric for evaluation\n",
        "metric = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "   logits, labels = eval_pred\n",
        "   predictions = np.argmax(logits, axis=-1)\n",
        "   return metric.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "id": "bINI3GU8bNJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training parameters and objects\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "   output_dir=\"test_trainer\",\n",
        "   #evaluation_strategy=\"epoch\",\n",
        "   per_device_train_batch_size=1,  # Reduce batch size here\n",
        "   per_device_eval_batch_size=1,    # Optionally, reduce for evaluation as well\n",
        "   gradient_accumulation_steps=4,\n",
        "   report_to=None\n",
        "   )\n",
        "\n",
        "trainer = Trainer(\n",
        "   model=model,\n",
        "   args=training_args,\n",
        "   train_dataset=small_train_dataset,\n",
        "   eval_dataset=small_eval_dataset,\n",
        "   compute_metrics=compute_metrics,\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "e20cn0lnbWGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the model performance before fine-tuning\n",
        "trainer.evaluate()"
      ],
      "metadata": {
        "id": "AyHRKtLifo-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "8zunm2V1fp6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the model performance after fine-tuning\n",
        "trainer.evaluate()"
      ],
      "metadata": {
        "id": "R9MvdO5HVa4M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}